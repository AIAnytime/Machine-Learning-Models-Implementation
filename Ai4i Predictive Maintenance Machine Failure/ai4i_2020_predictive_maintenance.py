# -*- coding: utf-8 -*-
"""AI4I 2020 Predictive Maintenance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EPhjz5gcUOKs77FVQvbpeJNrON8IpvIb
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""Data Link: https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset"""

data = pd.read_csv("ai4i2020.csv")

data

data['Machine failure'].unique()

data['Machine failure'].value_counts()

"""## It is a class imbalance problem.

# EDA
"""

data.info()

#check missing value
data.isna().sum()

data['Type'].unique()

"""# How to handle categorical column?
- One Hot Encoding

# Data Preparation
"""

def data_preparation(df):
  df = df.copy()

  #drop unnecessary columns
  df = df.drop(["UDI", "Product ID", "TWF", "HDF", "PWF", "OSF", "RNF"], axis=1)

  return df

X = data_preparation(data)

X

"""# Task
- To find "Machine Failure" if yes then 1 otherwise 0

# How we can do it?
- Traditional ML library "Scikit Learn"
- PyCaret (low code)

1. SK Learn 
- Pipeline
- Individual algorithm

# Using PyCaret
"""

!pip install pycaret

import pycaret.classification as pyc

dir(pyc)

"""- setup initialization, setup()
- compare_models()
- create_model()
- tune_model()
- predict_model
-save_model()
"""

pyc.setup(
    data = X,
    target = "Machine failure",
    train_size = 0.8,
    normalize = True
)

pyc.compare_models()

best_model = pyc.create_model('lightgbm')

print(best_model)

pyc.evaluate_model(best_model)

tuned_lgbm_model = pyc.tune_model(best_model)

pyc.evaluate_model(tuned_lgbm_model)

pyc.save_model(best_model, "machine_failure")

"""## Using Sklearn's Pipeline"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
# no need to scale the data for tree-based model, only for linear models
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.linear_model import LogisticRegression

from sklearn.metrics import plot_confusion_matrix, classification_report

data

def preprocess_inputs(df):
  df = df.copy()

  #drop unnecessary columns
  df = df.drop(["UDI", "Product ID", "TWF", "HDF", "PWF", "OSF", "RNF"], axis=1)

  #X(features) and y(target/class/labels)
  X = df.drop('Machine failure', axis=1)
  y = df['Machine failure']

  #split
  X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, shuffle=True, random_state=1)

  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess_inputs(data)

X_train

y_train

print(len(X_train))
print(len(X_test))
print(len(y_train))
print(len(y_test))

"""## Benefit of Sklearn pipeline
- you can pass multiple steps and transformers in one function
"""

single_transformer = Pipeline(steps=[
                                     ("encode", OneHotEncoder(sparse=False))
])

col_transformer = ColumnTransformer(transformers=[
                                                  ("colencode", single_transformer, ['Type'])
], remainder = 'passthrough')

model = Pipeline(steps=[
                        ("coltransform", col_transformer),
                        ("scale", StandardScaler()),
                        ("classifier", LogisticRegression())
])

clf = model.fit(X_train, y_train)

print(clf)

"""# Evaluation"""

score = clf.score(X_test, y_test)
print("Model score is:", np.round(score*100), "%")

y_pred = clf.predict(X_test)
print(y_pred)

plot_confusion_matrix(clf, X_test, y_test, labels=clf.classes_)

clr = classification_report(y_test, y_pred, labels=clf.classes_)
print(clr)

import pickle

# save the model to disk
filename = 'logreg_model.pkl'
pickle.dump(clf, open(filename, 'wb'))


# -*- coding: utf-8 -*-
"""Wireless Indoor Localization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1laeO83N5EaDwAAMCwhTCnTqhOZwwHEro
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import plot_confusion_matrix, classification_report

"""## Data Link: https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization#

"""

data = pd.read_csv("wifi_localization.txt",  delimiter = "\t", names= ['f1','f2','f3', 'f4', 'f5', 'f6', 'f7', 'class'])

data

"""## We don't have any column name given by the data owners. The first 7 columns are the features as these are the wifi signals recorded on a smartphone.

Target/Task: The last column that is a multiclass distribution and we need to classify those.

# Basic EDA
"""

data.info()

data.isna().sum()

data['class'].unique()

data['class'].value_counts()

def preprocess_inputs(df):
  df = df.copy()

  # X and y
  X = df.drop("class", axis=1)
  y = df['class']

  #split
  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)

  #scaling the data
  scaler = StandardScaler()
  scaler.fit(X_train)
  X_train = pd.DataFrame(scaler.transform(X_train), index= X_train.index, columns = X_train.columns)
  X_test = pd.DataFrame(scaler.transform(X_test), index= X_test.index, columns = X_test.columns)
  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess_inputs(data)

X_train

X_test

y_train

"""## Training"""

logreg = LogisticRegression()
clf = logreg.fit(X_train, y_train)

score = clf.score(X_test, y_test)

print("Score:", np.round(score*100), "%")

y_pred = clf.predict(X_test)
y_pred

plot_confusion_matrix(clf, X_test, y_test, labels= clf.classes_)

clr = classification_report(y_test, y_pred, labels= clf.classes_)
print(clr)

"""# Using Sklearn's Pipeline"""

from sklearn.pipeline import Pipeline

model = Pipeline(steps=[
                        ("scaler", StandardScaler()),
                        ("logreg", LogisticRegression())
])

model.fit(X_train, y_train)

score = model.score(X_test, y_test)

print("Score:", np.round(score*100), "%")

"""# Using PyCaret"""

!pip install pycaret

import pycaret.classification as pyc

pyc.setup(
    data= data,
    target = 'class',
    train_size=0.7,
    normalize = True
)

pyc.compare_models()

best_model = pyc.create_model('et')

pyc.evaluate_model(best_model)
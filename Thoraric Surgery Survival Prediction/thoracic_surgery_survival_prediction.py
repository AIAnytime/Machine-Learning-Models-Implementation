# -*- coding: utf-8 -*-
"""Thoracic Surgery Survival Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14U-giq1-rPTtBndoj_d_maYx56WKv_zg

# DATA:
Link: https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data

- We need to load arff in pandas dataframe using below function.
"""

from scipy.io import arff
import pandas as pd

data = arff.loadarff('ThoraricSurgery.arff')
df = pd.DataFrame(data[0])

df.head()

"""## We need to decode the byte in string values in the multiple columns as below:"""

def arff_data(df):
  df = df.copy()
  #we need to decode the byte from all the columns
  df['DGN'] = df['DGN'].str.decode('utf-8')
  df['PRE6'] = df['PRE6'].str.decode('utf-8')
  df['PRE7'] = df['PRE7'].str.decode('utf-8')
  df['PRE8'] = df['PRE8'].str.decode('utf-8')
  df['PRE9'] = df['PRE9'].str.decode('utf-8')
  df['PRE10'] = df['PRE10'].str.decode('utf-8')
  df['PRE11'] = df['PRE11'].str.decode('utf-8')
  df['PRE14'] = df['PRE14'].str.decode('utf-8')
  df['PRE17'] = df['PRE17'].str.decode('utf-8')
  df['PRE19'] = df['PRE19'].str.decode('utf-8')
  df['PRE25'] = df['PRE25'].str.decode('utf-8')
  df['PRE30'] = df['PRE30'].str.decode('utf-8')
  df['PRE32'] = df['PRE32'].str.decode('utf-8')
  df['Risk1Yr'] = df['Risk1Yr'].str.decode('utf-8')
  

  return df

X = arff_data(df)

X

"""# EDA"""

X.info()

# check missing value
X.isna().sum()

"""## No missing value."""

# find the correlation between the columns (numerical)
X.corr()

X['Risk1Yr'].value_counts()

"""# Class Imbalance problem."""

X['DGN'].unique()

X['PRE6'].unique()

X['PRE14'].unique()

"""## One hot encoding needed for below columns:
- DGN
- PRE6
- PRE14

# Narrative:
- Features: all apart from the last column
- Target: Risk1Yr

# We will do all the 3 ways:
- Individual implementation
- Sklearn's Pipeline
- PyCaret

# Individual Implementation 
- Logistic Regression
- RandomForest Classifier
- DecisionTree Classifier

### Tree based models don't require scaled data so we are not going to use StandardScaler for tree-based models.

## We will use scaled data for linear models like Logistic Regression.
mean of 0 and variance of 1.
"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import matthews_corrcoef, plot_confusion_matrix, classification_report

X.columns

def preprocess_inputs(df):
  df = df.copy()

  #making columns name to lower case
  df.rename(columns={'DGN': 'dgn',
                     'PRE4': 'pre4',
                     'PRE5': 'pre5',
                     'PRE6': 'pre6',
                     'PRE7': 'pre7',
                     'PRE8': 'pre8',
                     'PRE9': 'pre9',
                     'PRE10': 'pre10',
                     'PRE11': 'pre11',
                     'PRE14': 'pre14',
                     'PRE17': 'pre17',
                     'PRE19': 'pre19',
                     'PRE25': 'pre25',
                     'PRE30': 'pre30',
                     'PRE32': 'pre32',
                     'AGE': 'age',
                     'Risk1Yr': 'label'}, inplace = True)
  
  #converting boolean columns with 1 and 0 (1 for T and 0 for F)
  df['pre7'] = df['pre7'].apply(lambda x: 1  if x == 'T' else 0)
  df['pre8'] = df['pre8'].apply(lambda x:1 if x == 'T' else 0)
  df['pre9'] = df['pre9'].apply(lambda x:1 if x == 'T' else 0)
  df['pre10'] = df['pre10'].apply(lambda x:1 if x == 'T' else 0)
  df['pre11'] = df['pre11'].apply(lambda x:1 if x== 'T' else 0)
  df['pre17'] = df['pre17'].apply(lambda x:1 if x == 'T' else 0)
  df['pre19'] = df['pre19'].apply(lambda x:1 if x == 'T' else 0)
  df['pre25'] = df['pre25'].apply(lambda x:1 if x == 'T' else 0)
  df['pre30'] = df['pre30'].apply(lambda x:1 if x== 'T' else 0)
  df['pre32'] = df['pre32'].apply(lambda x:1 if x== 'T' else 0)
  df['label'] = df['label'].apply(lambda x:1 if x == 'T' else 0)

  #one hot encode
  dgn_dummies = pd.get_dummies(df['dgn'])
  df = pd.concat([df, dgn_dummies], axis=1)
  pre6_dummies = pd.get_dummies(df['pre6'])
  df = pd.concat([df, pre6_dummies], axis=1)
  pre14_dummies = pd.get_dummies(df['pre14'])
  df = pd.concat([df, pre14_dummies], axis=1)
  df = df.drop(['dgn', 'pre6', 'pre14'], axis=1)

  # features and label
  feat = df.drop("label", axis=1)
  target = df['label']

  #split
  X_train, X_test, y_train, y_test = train_test_split(feat, target, train_size= 0.7, shuffle=True, random_state=1)

  #scale the data for Logistic Regression
  scaler = StandardScaler()
  X_train = pd.DataFrame(scaler.fit_transform(X_train), index = X_train.index, columns= X_train.columns)

  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess_inputs(X)

X_train

y_train

"""## Training and Evaluation"""

log_reg = LogisticRegression()
log_model = log_reg.fit(X_train, y_train)

y_pred_log = log_model.predict(X_test)
y_pred_log

plot_confusion_matrix(log_model, X_test, y_test, labels=log_model.classes_)

clr_log = classification_report(y_test, y_pred_log, labels=log_model.classes_)
print(clr_log)

"""#PyCaret"""

!pip install pycaret

import pycaret.classification as pcr

def pycaret_inputs(df):
  df = df.copy()

  #making columns name to lower case
  df.rename(columns={'DGN': 'dgn',
                     'PRE4': 'pre4',
                     'PRE5': 'pre5',
                     'PRE6': 'pre6',
                     'PRE7': 'pre7',
                     'PRE8': 'pre8',
                     'PRE9': 'pre9',
                     'PRE10': 'pre10',
                     'PRE11': 'pre11',
                     'PRE14': 'pre14',
                     'PRE17': 'pre17',
                     'PRE19': 'pre19',
                     'PRE25': 'pre25',
                     'PRE30': 'pre30',
                     'PRE32': 'pre32',
                     'AGE': 'age',
                     'Risk1Yr': 'label'}, inplace = True)
  
  #converting boolean columns with 1 and 0 (1 for T and 0 for F)
  df['pre7'] = df['pre7'].apply(lambda x: 1  if x == 'T' else 0)
  df['pre8'] = df['pre8'].apply(lambda x:1 if x == 'T' else 0)
  df['pre9'] = df['pre9'].apply(lambda x:1 if x == 'T' else 0)
  df['pre10'] = df['pre10'].apply(lambda x:1 if x == 'T' else 0)
  df['pre11'] = df['pre11'].apply(lambda x:1 if x== 'T' else 0)
  df['pre17'] = df['pre17'].apply(lambda x:1 if x == 'T' else 0)
  df['pre19'] = df['pre19'].apply(lambda x:1 if x == 'T' else 0)
  df['pre25'] = df['pre25'].apply(lambda x:1 if x == 'T' else 0)
  df['pre30'] = df['pre30'].apply(lambda x:1 if x== 'T' else 0)
  df['pre32'] = df['pre32'].apply(lambda x:1 if x== 'T' else 0)
  df['label'] = df['label'].apply(lambda x:1 if x == 'T' else 0)

 

  return df

pycaret_data = pycaret_inputs(X)

pycaret_data

pcr.setup(
    data = pycaret_data,
    target = 'label',
    train_size = 0.7,
    normalize = True
)

pcr.compare_models()

best_model = pcr.create_model('rf')

pcr.evaluate_model(best_model)

pcr.save_model(best_model, "rf_model")